{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the root directory to path\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szymonsadkowski/miniconda3/envs/mim-licence-plate/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usging device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from lib.model import get_model\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('gpu:0') if use_cuda is True else torch.device('cpu')\n",
    "model = get_model(half=use_cuda, device=device)\n",
    "model.max_det = 1\n",
    "print(f'usging device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_prediction(img: Image.Image) -> np.ndarray:\n",
    "    return model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Iterable\n",
    "\n",
    "\n",
    "DATASET_PATH = '/Users/szymonsadkowski/Downloads/images'\n",
    "NUM_IMAGES = 100\n",
    "\n",
    "def iter_images(start: int = 0, end: int = NUM_IMAGES) -> Iterable[Tuple[np.ndarray, np.ndarray, np.ndarray, int]]:\n",
    "    for i in range(start, end):\n",
    "        org = np.load(f'{DATASET_PATH}/original-{i}.npy')\n",
    "        d_patched = np.load(f'{DATASET_PATH}/patched-{i}.npy')\n",
    "        random_patched = np.load(f'{DATASET_PATH}/random-{i}.npy')\n",
    "        yield org / 255, d_patched / 255, random_patched / 255, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.segmentation import SuperPixler\n",
    "from lib.explanations import calculate_shap\n",
    "from lib.image import img_float_to_uint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPES = 60\n",
    "BATCH_SIZE = 250\n",
    "N_SEGMENTS = 30\n",
    "SIGMA = 0\n",
    "COMPACTNESS = 60\n",
    "\n",
    "\n",
    "def calc_avg_patch_contrib(contrib: np.ndarray) -> float:\n",
    "    return np.mean(contrib)\n",
    "\n",
    "def calc_var_patch_contrib(patch_contr: np.ndarray) -> float:\n",
    "    return np.var(patch_contr)\n",
    "\n",
    "def calc_mean_abs_patch_contrib_diff(contrib1: np.ndarray, contrib2: np.ndarray) -> float:\n",
    "    return np.mean(np.abs(contrib1 - contrib2))\n",
    "\n",
    "def calc_var_abs_patch_contrib_diff(contrib1: np.ndarray, contrib2: np.ndarray) -> float:\n",
    "    return np.var(np.abs(contrib1 - contrib2))\n",
    "\n",
    "def calc_most_positive_patch_invariant(contrib1: np.ndarray, contrib2: np.ndarray) -> bool:\n",
    "    return np.argmax(contrib1) == np.argmax(contrib2)\n",
    "\n",
    "def calc_most_negative_patch_invariant(contrib1: np.ndarray, contrib2: np.ndarray) -> bool:\n",
    "    return np.argmin(contrib1) == np.argmin(contrib2)\n",
    "\n",
    "def normalize_contrib(contrib: np.ndarray) -> np.ndarray:\n",
    "    return contrib / np.sum(np.abs(contrib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing image 0\n",
      "processing image 1\n",
      "processing image 2\n",
      "processing image 3\n",
      "processing image 4\n",
      "processing image 5\n",
      "processing image 6\n",
      "processing image 7\n",
      "processing image 8\n",
      "processing image 9\n",
      "processing image 10\n",
      "processing image 11\n",
      "processing image 12\n",
      "processing image 13\n",
      "processing image 14\n",
      "processing image 15\n",
      "processing image 16\n",
      "processing image 17\n",
      "processing image 18\n",
      "processing image 19\n",
      "processing image 20\n",
      "processing image 21\n",
      "processing image 22\n",
      "processing image 23\n",
      "processing image 24\n",
      "processing image 25\n",
      "processing image 26\n",
      "processing image 27\n",
      "processing image 28\n",
      "processing image 29\n",
      "processing image 30\n",
      "processing image 31\n",
      "processing image 32\n",
      "processing image 33\n",
      "processing image 34\n",
      "processing image 35\n",
      "processing image 36\n",
      "processing image 37\n",
      "processing image 38\n",
      "processing image 39\n",
      "processing image 40\n",
      "processing image 41\n",
      "processing image 42\n",
      "processing image 43\n",
      "processing image 44\n",
      "processing image 45\n",
      "processing image 46\n",
      "processing image 47\n",
      "processing image 48\n",
      "processing image 49\n",
      "processing image 50\n",
      "processing image 51\n",
      "processing image 52\n",
      "processing image 53\n",
      "processing image 54\n",
      "processing image 55\n",
      "processing image 56\n",
      "processing image 57\n",
      "processing image 58\n",
      "processing image 59\n",
      "processing image 60\n",
      "processing image 61\n",
      "processing image 62\n",
      "processing image 63\n",
      "processing image 64\n",
      "processing image 65\n",
      "processing image 66\n",
      "processing image 67\n",
      "processing image 68\n",
      "processing image 69\n",
      "processing image 70\n",
      "processing image 71\n",
      "processing image 72\n",
      "processing image 73\n",
      "processing image 74\n",
      "processing image 75\n",
      "processing image 76\n",
      "processing image 77\n",
      "processing image 78\n",
      "processing image 79\n",
      "processing image 80\n",
      "processing image 81\n",
      "processing image 82\n",
      "processing image 83\n",
      "processing image 84\n",
      "processing image 85\n",
      "processing image 86\n",
      "processing image 87\n",
      "processing image 88\n",
      "processing image 89\n",
      "processing image 90\n",
      "processing image 91\n",
      "processing image 92\n",
      "processing image 93\n",
      "processing image 94\n",
      "processing image 95\n",
      "processing image 96\n",
      "processing image 97\n",
      "processing image 98\n",
      "processing image 99\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "contribs = []\n",
    "\n",
    "\n",
    "for original, dpatched, random_patched, img_id in iter_images():  # floats arrs range [0, 1]\n",
    "    print(f'processing image {img_id}')\n",
    "\n",
    "    superpixler = SuperPixler(original, n_segments=N_SEGMENTS, sigma=SIGMA, compactness=COMPACTNESS)\n",
    "    detections = model(img_float_to_uint(original)).xyxy[0].cpu().numpy()\n",
    "    most_conf_det = np.argmax(detections[:, 4])\n",
    "    target_bbox = detections[most_conf_det, :4].reshape(1, 4)\n",
    "\n",
    "    # original\n",
    "    org_shap_v = calculate_shap(model, superpixler, target_bbox, nsamples=N_SAMPES, batch_size=BATCH_SIZE, half=use_cuda)\n",
    "\n",
    "    # dpatched\n",
    "    superpixler.image = dpatched\n",
    "    dpatch_shap_v = calculate_shap(model, superpixler, target_bbox, nsamples=N_SAMPES, batch_size=BATCH_SIZE, half=use_cuda)\n",
    "\n",
    "    # random patch\n",
    "    superpixler.image = random_patched\n",
    "    rand_patch_shap_v = calculate_shap(model, superpixler, target_bbox, nsamples=N_SAMPES, batch_size=BATCH_SIZE, half=use_cuda)\n",
    "\n",
    "\n",
    "    # calculate metrics\n",
    "    patch_contribs = [(org_shap_v, 'org'), (dpatch_shap_v, 'dpatch'), (rand_patch_shap_v, 'rand')]\n",
    "\n",
    "    contrib = {}\n",
    "    contrib['img_id'] = img_id\n",
    "    for patch_contr, name in patch_contribs:\n",
    "        contrib[f'shap_contrib_{name}'] = patch_contr\n",
    "\n",
    "    contribs.append(contrib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(contribs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mim-licence-plate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
